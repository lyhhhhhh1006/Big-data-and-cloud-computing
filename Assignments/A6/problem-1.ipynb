{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Working with RDDs\n",
    "\n",
    "This is an interactive PySpark session. Remember that when you open this notebook the `SparkContext` and `SparkSession` are already created, and they are in the `sc` and `spark` variables, respectively. You can run the following two cells to make sure that the Kernel is active.\n",
    "\n",
    "**Do not insert any additional cells than the ones that are provided.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/10/16 03:42:51 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "22/10/16 03:42:58 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext()\n",
    "spark = SparkSession.builder.appName(\"problem1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-44-232.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-amzn-0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=pyspark-shell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `top-1m.csv': File exists\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -put -l top-1m.csv top-1m.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, make an RDD called `top1m` that contains the contents of the file `top-1m.csv` that you placed into the cluster's HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1m = sc.textFile(\"top-1m.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one element in the RDD for each line in the file. The `.count()` method will compute how many lines are in the file. In the following cell, type the expression to count the lines in the `top1m` RDD. Run the cell and see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1m.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the `.com` domains\n",
    "\n",
    "How many of the websites in this RDD are in the .com domain?\n",
    "\n",
    "In the following cell, write an code snipped that finds the records with `.com` at the end of the line and counts them. (Hint: use a regular expression.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "end_w_com = top1m.filter(lambda x: re.match(\".*\\.com$\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "484593"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_w_com.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram the Top Level Domains (TLDs)\n",
    "\n",
    "What is the distribution of TLDs in the top 1 million websites? We can compute this using the RDD function `countByValue()` in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, write a function called `tld` (in Python) that takes a domain name string and outputs the top-level domain by grabbing the final characters after the last period in the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,google.com',\n",
       " '2,youtube.com',\n",
       " '3,facebook.com',\n",
       " '4,baidu.com',\n",
       " '5,wikipedia.org',\n",
       " '6,yahoo.com',\n",
       " '7,qq.com',\n",
       " '8,amazon.com',\n",
       " '9,taobao.com',\n",
       " '10,twitter.com']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1m.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tld(domain):\n",
    "    result = re.sub('.*\\\\.', '', domain)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, map the `top1m` RDD using `tld` into a new RDD called `tlds`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlds = top1m.map(lambda x: tld(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following two cells, evaluate `top1m.first()` and  `tlds.first()` to see if the first line of `top1m` transformed by `tld` is properly represented as the first line of `tlds`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,google.com'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1m.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'com'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlds.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first 50 elements of `top1m` by evaluating `top1m.take(50)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,google.com',\n",
       " '2,youtube.com',\n",
       " '3,facebook.com',\n",
       " '4,baidu.com',\n",
       " '5,wikipedia.org',\n",
       " '6,yahoo.com',\n",
       " '7,qq.com',\n",
       " '8,amazon.com',\n",
       " '9,taobao.com',\n",
       " '10,twitter.com',\n",
       " '11,google.co.in',\n",
       " '12,tmall.com',\n",
       " '13,instagram.com',\n",
       " '14,live.com',\n",
       " '15,vk.com',\n",
       " '16,sohu.com',\n",
       " '17,jd.com',\n",
       " '18,sina.com.cn',\n",
       " '19,reddit.com',\n",
       " '20,weibo.com',\n",
       " '21,google.co.jp',\n",
       " '22,yandex.ru',\n",
       " '23,360.cn',\n",
       " '24,blogspot.com',\n",
       " '25,login.tmall.com',\n",
       " '26,linkedin.com',\n",
       " '27,pornhub.com',\n",
       " '28,google.ru',\n",
       " '29,netflix.com',\n",
       " '30,google.com.br',\n",
       " '31,google.com.hk',\n",
       " '32,google.co.uk',\n",
       " '33,bongacams.com',\n",
       " '34,yahoo.co.jp',\n",
       " '35,google.fr',\n",
       " '36,csdn.net',\n",
       " '37,t.co',\n",
       " '38,google.de',\n",
       " '39,ebay.com',\n",
       " '40,microsoft.com',\n",
       " '41,alipay.com',\n",
       " '42,office.com',\n",
       " '43,twitch.tv',\n",
       " '44,msn.com',\n",
       " '45,bing.com',\n",
       " '46,xvideos.com',\n",
       " '47,microsoftonline.com',\n",
       " '48,mail.ru',\n",
       " '49,pages.tmall.com',\n",
       " '50,ok.ru']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1m.take(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the same thing with the `tlds` RDD to make sure that the first 50 lines were properly transformed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['com',\n",
       " 'com',\n",
       " 'com',\n",
       " 'com',\n",
       " 'org',\n",
       " 'com',\n",
       " 'com',\n",
       " 'com',\n",
       " 'com',\n",
       " 'com',\n",
       " 'in',\n",
       " 'com',\n",
       " 'com',\n",
       " 'com',\n",
       " 'com',\n",
       " 'com',\n",
       " 'com',\n",
       " 'cn',\n",
       " 'com',\n",
       " 'com',\n",
       " 'jp',\n",
       " 'ru',\n",
       " 'cn',\n",
       " 'com',\n",
       " 'com',\n",
       " 'com',\n",
       " 'com',\n",
       " 'ru',\n",
       " 'com',\n",
       " 'br',\n",
       " 'hk',\n",
       " 'uk',\n",
       " 'com',\n",
       " 'jp',\n",
       " 'fr',\n",
       " 'net',\n",
       " 'co',\n",
       " 'de',\n",
       " 'com',\n",
       " 'com',\n",
       " 'com',\n",
       " 'com',\n",
       " 'tv',\n",
       " 'com',\n",
       " 'com',\n",
       " 'com',\n",
       " 'com',\n",
       " 'ru',\n",
       " 'com',\n",
       " 'ru']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlds.take(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a better way to make these comparisons rather than looking back and forth between the raw and transformed data. Use the `zip()` function with both `take` outputs to print both the raw and extracted data versions on the same line, one line per record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1,google.com', 'com'),\n",
       " ('2,youtube.com', 'com'),\n",
       " ('3,facebook.com', 'com'),\n",
       " ('4,baidu.com', 'com'),\n",
       " ('5,wikipedia.org', 'org'),\n",
       " ('6,yahoo.com', 'com'),\n",
       " ('7,qq.com', 'com'),\n",
       " ('8,amazon.com', 'com'),\n",
       " ('9,taobao.com', 'com'),\n",
       " ('10,twitter.com', 'com'),\n",
       " ('11,google.co.in', 'in'),\n",
       " ('12,tmall.com', 'com'),\n",
       " ('13,instagram.com', 'com'),\n",
       " ('14,live.com', 'com'),\n",
       " ('15,vk.com', 'com'),\n",
       " ('16,sohu.com', 'com'),\n",
       " ('17,jd.com', 'com'),\n",
       " ('18,sina.com.cn', 'cn'),\n",
       " ('19,reddit.com', 'com'),\n",
       " ('20,weibo.com', 'com'),\n",
       " ('21,google.co.jp', 'jp'),\n",
       " ('22,yandex.ru', 'ru'),\n",
       " ('23,360.cn', 'cn'),\n",
       " ('24,blogspot.com', 'com'),\n",
       " ('25,login.tmall.com', 'com'),\n",
       " ('26,linkedin.com', 'com'),\n",
       " ('27,pornhub.com', 'com'),\n",
       " ('28,google.ru', 'ru'),\n",
       " ('29,netflix.com', 'com'),\n",
       " ('30,google.com.br', 'br'),\n",
       " ('31,google.com.hk', 'hk'),\n",
       " ('32,google.co.uk', 'uk'),\n",
       " ('33,bongacams.com', 'com'),\n",
       " ('34,yahoo.co.jp', 'jp'),\n",
       " ('35,google.fr', 'fr'),\n",
       " ('36,csdn.net', 'net'),\n",
       " ('37,t.co', 'co'),\n",
       " ('38,google.de', 'de'),\n",
       " ('39,ebay.com', 'com'),\n",
       " ('40,microsoft.com', 'com'),\n",
       " ('41,alipay.com', 'com'),\n",
       " ('42,office.com', 'com'),\n",
       " ('43,twitch.tv', 'tv'),\n",
       " ('44,msn.com', 'com'),\n",
       " ('45,bing.com', 'com'),\n",
       " ('46,xvideos.com', 'com'),\n",
       " ('47,microsoftonline.com', 'com'),\n",
       " ('48,mail.ru', 'ru'),\n",
       " ('49,pages.tmall.com', 'com'),\n",
       " ('50,ok.ru', 'ru')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = top1m.take(50)\n",
    "new = tlds.take(50)\n",
    "zipped = zip(raw,new)\n",
    "list(zipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, `tlds.countByValue()` would give us a list of each TLD and the number of times that it appears in the top1m file. Note that this function returns the results as a `defaultDict` in the Python environment, not as an RDD. But we want it reverse sort it by count. To do this, we can set a variable called `tlds_and_counts` equal to `tlds.countByValue()` and then reverse the order, sort, and take the top 50, like this:\n",
    "\n",
    "```\n",
    "tlds_and_counts = tlds.countByValue()\n",
    "counts_and_tlds = [(count,domain) for (domain,count) in tlds_and_counts.items()]\n",
    "counts_and_tlds.sort(reverse=True)\n",
    "counts_and_tlds[0:50]\n",
    "```\n",
    "\n",
    "In the following cell, run the code above to produce the Python Dictionary of the top 50 domains, sorted by descending count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(484593, 'com'),\n",
       " (45610, 'org'),\n",
       " (41336, 'net'),\n",
       " (40239, 'ru'),\n",
       " (34374, 'de'),\n",
       " (28186, 'br'),\n",
       " (18616, 'uk'),\n",
       " (16903, 'pl'),\n",
       " (15507, 'ir'),\n",
       " (12239, 'it'),\n",
       " (12041, 'in'),\n",
       " (10346, 'fr'),\n",
       " (9411, 'au'),\n",
       " (8753, 'jp'),\n",
       " (8414, 'info'),\n",
       " (8070, 'cz'),\n",
       " (6518, 'es'),\n",
       " (6340, 'nl'),\n",
       " (6262, 'ua'),\n",
       " (6086, 'co'),\n",
       " (5706, 'cn'),\n",
       " (5634, 'ca'),\n",
       " (5596, 'io'),\n",
       " (5246, 'tw'),\n",
       " (5009, 'eu'),\n",
       " (4812, 'kr'),\n",
       " (4794, 'gr'),\n",
       " (4788, 'ch'),\n",
       " (4512, 'mx'),\n",
       " (3841, 'ro'),\n",
       " (3836, 'se'),\n",
       " (3631, 'no'),\n",
       " (3608, 'at'),\n",
       " (3484, 'me'),\n",
       " (3469, 'tv'),\n",
       " (3392, 'be'),\n",
       " (3267, 'za'),\n",
       " (3266, 'hu'),\n",
       " (3076, 'vn'),\n",
       " (3039, 'sk'),\n",
       " (3020, 'us'),\n",
       " (3013, 'ar'),\n",
       " (2798, 'edu'),\n",
       " (2769, 'dk'),\n",
       " (2553, 'tr'),\n",
       " (2439, 'pt'),\n",
       " (2300, 'biz'),\n",
       " (2256, 'cl'),\n",
       " (2228, 'id'),\n",
       " (2154, 'fi')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlds_and_counts = tlds.countByValue()\n",
    "counts_and_tlds = [(count,domain) for (domain,count) in tlds_and_counts.items()]\n",
    "counts_and_tlds.sort(reverse=True)\n",
    "counts_and_tlds[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** `top1m.collect()[0:50]` and `top1m.take(50)` produce the same result. Which one is more efficient and why? Put your answer in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my opinion, top1m.take(50) is more efficient and needs less running time, because for top1m.collect()[0:50], the collect function will compute all the content and metadata of the dataframe and show the top 50. top1m.take(50) can be used to shows content and structure/metadata for a limited number of rows for a very large dataset, it can flatten out the data and show us the top 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Run the following cell to export your final ordered results of domain into a json file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(counts_and_tlds, fp = open('problem-1-soln.json','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you finish this problem, click on the File -> 'Save and Checkpoint' in the menu bar to make sure that the latest version of the workbook file is saved. Also, before you close this notebook and move on, make sure you disconnect your SparkContext, otherwise you will not be able to re-allocate resources. Remember, you will commit the .ipynb file to the repository for submission (in the master node terminal.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
